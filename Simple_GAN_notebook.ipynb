{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple-GAN-notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkBhM87n7nZ2P9lU+Apkx0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jivemachine/GAN/blob/main/Simple_GAN_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxuaEem-RcIr"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t9iuTNFRYi0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngji_ae6YEzK",
        "outputId": "034ada28-aa53-4884-963b-91e91a22aa6a"
      },
      "source": [
        "# importing the MNIST fashion dataset from keras\n",
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "X_train_full = X_train_full.astype(np.float32) / 255\n",
        "X_test = X_test.astype(np.float32) / 255\n",
        "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRaeh5fHRhg8"
      },
      "source": [
        "# building the generator\n",
        "size = 30 # size of images we are generating\n",
        "\n",
        "generator = keras.models.Sequential([\n",
        "      keras.layers.Dense(100, activation='selu', input_shape=[size]),\n",
        "      keras.layers.Dense(150, activation='selu'),\n",
        "      keras.layers.Dense(28 * 28, activation='sigmoid'),\n",
        "      keras.layers.Reshape([28, 28])\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiwEp_DnSPuN"
      },
      "source": [
        "# building the discriminator\n",
        "discriminator = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28,28]),\n",
        "    keras.layers.Dense(150, activation='selu'),\n",
        "    keras.layers.Dense(100, activation='selu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkTLN4SGTQh0"
      },
      "source": [
        "# putting our simple gan together\n",
        "gan = keras.models.Sequential([generator, discriminator])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn7YauqNTpHN"
      },
      "source": [
        "# compiling the model\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
        "discriminator.trainable = False # the discriminator should not be trained during the second phase, before our gan\n",
        "gan.compile(loss='binary_crossentropy', optimizer='rmsprop')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V109C-MTT95q"
      },
      "source": [
        "# since the training loop is unusual we need to write a custom training loop for the model\n",
        "batch_size = 32\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_E6432gUlWo"
      },
      "source": [
        "# training loop\n",
        "def train_gan(gan, dataset, batch_size, size, n_epochs=50):\n",
        "  generator, discriminator = gan.layers\n",
        "  for epoch in range(n_epochs):\n",
        "    for X_batch in dataset:\n",
        "      # phase 1 - training the discriminator\n",
        "      noise = tf.random.normal(shape=[batch_size, size])\n",
        "      generated_images = generator(noise)\n",
        "      X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "      y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "      discriminator.trainable = False\n",
        "      discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "      # phase 2 - training the generator\n",
        "      noise = tf.random.normal(shape=[batch_size, size])\n",
        "      y2 = tf.constant([[1.]] * batch_size)\n",
        "      discriminator.trainable = False\n",
        "      gan.train_on_batch(noise, y2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIwiMdJwZMRR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}